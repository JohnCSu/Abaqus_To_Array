# Parametric Machine Learning With Abaqus FEA

<img title="a title" alt="Alt text" src="Presentation2.gif">


This Repo demonstrates a workflow for parameterised machine learning using Abaqus FEA results as training data. There are 4 main scripts to run in respective order:

- `Step1_TubeCrush.py` - Runs the model at different parameters based on the values provided in parameters.txt. This creates our training dataset (Note our test dataset has been created already)

- `Step2_ExportResults.py` - Extracts the results from the ODB files generated from step 1 into .mat files

- `Step3_Train_Networks.py` - Extract the .mat files from Step 2 into pytorch tensors and train the neural network on the generated FEA data. Generate prediections for data in Test folder and Convert the data back into .mat format. `training.ipynb` is a notebook version of the script

- `Step4_From_NN_To_Abaqus.py` - From the .mat results generated by Step 3, Reconstruct the mesh for each Test Case and into Abaqus ODB format to be viewed

**NOTE YOU DONT HAVE TO RUN STEP 1 and 2**. The results already exist in the ML_Folder.

This workflow is designed to be run in Abaqus 2024 and upwards (for abaqus versions 2025 and later please first upgrade the CAE file by opening Crush.cae and TubeCrush.odb in Abaqus CAE first)

Steps 1,2 and 4 are to be run via the Abaqus CAE kernel (e.g. from cmd line abaqus cae script= python_script.py). Step 3, the training of the network can either be done via Abaqus CAE python or outside of it.

The following packages need to be installed. Any version should be fine:
- Numpy
- Scipy
- pytorch

The main benefits you may find from this example are the functions to extract results from ODB files into a neutral format which is pretty general for different Abaqus models

For those unfamiliar with Neural networks the main trick here is that outputs and inputs are normalized to values between [0,1] based on the training data. When exporting the network results we then unnormalise the results back to the correct units. Because we aren't employing PINN (physics informed neural network) training, we can do normalization to each input and output individually. If PINN training is used we would need to use dimensional analysis to ensure units are consistent.

## License 
MIT